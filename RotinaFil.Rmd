---
title: "Health"
author: "fildalboni"
date: "04/11/2021"
output: html_document
---
---
title: "BI PR Produtivo new version"
author: "Equipe CIGE"
date: "11/08/2021"
output: html_document
---

```{r setup, include=FALSE}

# setting the chunck configuration
knitr::opts_chunk$set(echo = FALSE, 
                      comment = NA,
                      warning = FALSE,
                      error = FALSE, 
                      message = FALSE,
                      tidy = TRUE)

# setting main root in personal drive
print(getwd())
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
dwdir = print(getwd()) # main personal project root

{ 
  # Check if the packages that we need are installed
  want = c("RCurl", "tidyverse", "readr", "zoo", "googledrive", "RCurl", 
           "gsheet", "stringr", "knitr", "data.table", "readxl", "qdapRegex")
  have = want %in% rownames(installed.packages())
  # Install the packages that we miss
  if ( any(!have) ) { install.packages( want[!have] ) }
  # Load the packages
  junk <- lapply(want, library, character.only = T)
  # Remove the objects we created
  rm(have, want, junk)
} # Import packages

# setting principal roots (dw + first 3 database words + data type)
dwagriraw = paste0(dwdir, "/db/raw/agricultural")

```

```{r health}

{
# import city database
fCity = read_delim("C:/Users/CepaTech/Documents/Profissional/SEPL/PowerBi 3/Banco de Dados/citiy/fcity2.csv", 
                       ";", escape_double = FALSE, 
                       locale = locale(decimal_mark = ",",
                                       grouping_mark = ".", 
                                       encoding = "UTF-8"),
                       trim_ws = TRUE)


#Rename columns
colnames(fCity)[1] <- "city_code"

# creating a list 
temp = fCity 
temp = as.vector(temp)
temp = as.vector(fCity$city_code)

# Import population database
fPop <- read_excel("~/Profissional/SEPL/PowerBi 3/Banco de Dados/population/pop_pr.xlsx")

#Rename
colnames(fPop)[1:2] <- c("city", "variable")

fPop <- melt(fPop)

colnames(fPop)[3:4] <- c("year", "parameter")

fPop[, 2] <- "Population"

fPop <- fPop[!is.na(fPop$parameter), ]

} # parameters database


{
  # Step 1: Import hospitalization database
  dHospi <- read.delim("~/Profissional/SEPL/PowerBi 3/Banco de Dados/health/Hospitalizations.csv",
                     sep=";")
  
  # Step 2: Rename columns
  colnames(dHospi)[1:2] <- c("city", "variable")
  colnames(dHospi) <- gsub("X","", colnames(dHospi))
  
  # Step 3: Join city code with database
  dHospi <- left_join(dHospi, fCity, by = "city")
  
  #Step 4: rearrange dHospi
  dHospi <- dHospi[, c(1, 14, 2:13)]
  
}# Part 1: Import and Join with city_code

{
  # Step 1: Separate variable, group and type columns
  dHospi <- cbind(dHospi, 
                   as.data.frame(do.call("rbind", strsplit(as.character(dHospi$variable),' - '))))
  dHospi <- dHospi[, !colnames(dHospi) == "V2"]
  dHospi <- cbind(dHospi, 
                   as.data.frame(do.call("rbind",
                                         ex_between(dHospi$V3, "(", ")", 
                                                    include.markers = TRUE,
                                                    trim = TRUE,
                                                    ))))
  colnames(dHospi)[15:17] <- c("group", "variable", "standard")
  dHospi <- dHospi[, c(1:2, 15:17, 4:14)]
  dHospi$variable <- gsub("\\s*\\([^\\)]+\\)","", dHospi$variable)
  dHospi$standard <- gsub("[()]", "", dHospi$standard)
  
  # Step 2: Create column group_code
  dHospi$group <- "Hospitalization"
  dHospi$group_code <- 1
  
  # Step 3: Create column variable_code
  dHospi <- dHospi %>%
    group_by(city) %>%
    mutate(variable_code = sequence(n()))
  
  # Step 4: Create standard_code column
  dHospi$standard <- case_when(is.na(dHospi$standard) ~ "pessoas", TRUE ~ dHospi$standard) 
  standard <- unique(dHospi$standard)
  fstand <- as.data.frame(standard) %>%
    mutate(standard_code = sequence(n()))
  dHospi <- left_join(dHospi, fstand, by = "standard")
  
} # Part 2: Create group_code, variable_code and type_code

{ 
  # selecting variables
  data = files %>%
    select(D1C, D2C, D3C, D4C, MC, V) %>%
    filter(V > 0)
  
  # renaming variables
  names(data) = c("code", "year", "code_category", "code_variable", "code_standard", "result")
  
  # including group variable
  data = data %>%
    mutate(code_group = 1)
  
  # exporting database
  write.csv2(data, "C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/DATABASE/dLivestock.csv", 
             row.names=FALSE, na = "")
  
} # organizing database 

{
  # category
  fLivestockCategory = data %>%
    group_by(code_group) %>%
    dplyr::summarise(n = n()) %>% 
    select(-n) %>%
    mutate(group = "PecuÃ¡ria")
  
  # variable
  fLivestockVariable = files %>%
    group_by(D4C, D4N) %>%
    dplyr::summarise(n = n()) %>%
    select(-n)
  
  # renaming variables
  names(fLivestockVariable) = c("code_variable", "variable")
  
  # variable
  fLivestockStandard = files %>%
    group_by(MC, MN) %>%
    dplyr::summarise(n = n()) %>%
    select(-n)
  
  # renaming variables
  names(fLivestockStandard) = c("code_standard", "standard")
  
} # creating filter databases

{

# setting folder  
fold = "C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/WORKFLOW"

# getting all files in the directories, recursively
f = list.files(fold, include.dirs = F, full.names = T, recursive = T)

# removing the files
file.remove(f)
  
} # cleaning workspace folder
  
} # livestock database

{
  
for (file in 1:399){ 

data = get_sidra(x = 5457,
          period = c(last = "10"),
          geo = c("State","City"),
          header = FALSE,
          format = 4,
          geo.filter = list("City" = temp[file], "State" = 41),
          category = list("all"),
          classific = "all")

# setting the directory      
setwd("C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/WORKFLOW") 

# Saving a single object to a file
saveRDS(data, paste(file, ".rds"))
 
} # creating looping for files

{
  
# Step 1: set the working directory (where files are saved)
setwd("C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/WORKFLOW") 
  
# Step 2: get all the right file names
file_names = list.files(getwd())
file_names = file_names[grepl(".rds",file_names)]
    
# Step 3: get the read.csv function working
files = readRDS("1 .rds")
    
# Step 4: use lapply to apply the read.csv function to all values of file_names
files = lapply(file_names, readRDS)
list = files
files = rbindlist(files, fill = TRUE)
    
# check structure of new data set
str(files)
    
} # join databases

{ 
  # selecting variables
  data = files %>%
    select(D1C, D2C, D3C, D4C, MC, V) %>%
    filter(V > 0)
  
  # renaming variables
  names(data) = c("code", "year", "code_category", "code_variable", "code_standard", "result")
  
  # including group variable
  data = data %>%
    mutate(code_group = 2) %>%
    filter(code_variable != 0)
  
  # exporting database
  write.csv2(data, "C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/DATABASE/dFarming.csv", 
             row.names=FALSE, na = "")
  
} # organizing database 

{
  # category
  fFarmingCategory = data %>%
    group_by(code_group) %>%
    dplyr::summarise(n = n()) %>% 
    select(-n) %>%
    mutate(group = "Agricultura")
  
  # variable
  fFarmingVariable = files %>%
    group_by(D4C, D4N) %>%
    dplyr::summarise(n = n()) %>%
    select(-n) %>%
    filter(D4C != 0)
  
  # renaming variables
  names(fFarmingVariable) = c("code_variable", "variable")
  
  # variable
  fFarmingStandard = files %>%
    group_by(MC, MN) %>%
    dplyr::summarise(n = n()) %>%
    select(-n)
  
  # renaming variables
  names(fFarmingStandard) = c("code_standard", "standard")
  
} # creating filter databases
  
{

# setting folder  
fold = "C:/Users/jrton/OneDrive/BD/BI/AGRIBUSINESS/WORKFLOW"

# getting all files in the directories, recursively
f = list.files(fold, include.dirs = F, full.names = T, recursive = T)

# removing the files
file.remove(f)
  
} # cleaning workspace folder

} # farming database

```
